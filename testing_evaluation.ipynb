{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.791      0.633      0.719      0.518\n",
      "                  Belt       1021         10          0          0          0          0\n",
      "                  Face       1021       1904      0.951      0.917      0.948      0.746\n",
      "                 Glove       1021        195      0.653      0.338      0.462      0.278\n",
      "               Goggles       1021        107      0.825      0.308      0.584      0.277\n",
      "                  Hand       1021       2406      0.907      0.776      0.858       0.54\n",
      "                  Head       1021       2747      0.975      0.917      0.955      0.878\n",
      "                Helmet       1021        541      0.973      0.861      0.922      0.599\n",
      "                 Pants       1021       1682      0.882      0.704      0.813      0.604\n",
      "                 Shirt       1021       2333       0.95      0.879       0.93      0.737\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\0.001_0.0001_0.95_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.0001_0.95_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [01:02<00:00,  7.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.804        0.6      0.713       0.51\n",
      "                  Belt       1021         10          0          0          0          0\n",
      "                  Face       1021       1904      0.962      0.899      0.942      0.742\n",
      "                 Glove       1021        195      0.704      0.292      0.492      0.307\n",
      "               Goggles       1021        107      0.923      0.112      0.519      0.213\n",
      "                  Hand       1021       2406      0.917      0.766      0.857      0.533\n",
      "                  Head       1021       2747      0.967      0.915      0.953      0.872\n",
      "                Helmet       1021        541      0.961       0.83      0.905      0.598\n",
      "                 Pants       1021       1682      0.873      0.706      0.816      0.598\n",
      "                 Shirt       1021       2333      0.927      0.879       0.93      0.725\n",
      "Speed: 0.5ms preprocess, 2.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving testing\\0.001_0.0001_0.95_True\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.0001_0.95_True\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925        0.9      0.644      0.782      0.529\n",
      "                  Belt       1021         10          1        0.1       0.55       0.11\n",
      "                  Face       1021       1904      0.953      0.909      0.944      0.745\n",
      "                 Glove       1021        195      0.678      0.313      0.495      0.297\n",
      "               Goggles       1021        107      0.838       0.29      0.563       0.26\n",
      "                  Hand       1021       2406        0.9      0.793      0.867      0.537\n",
      "                  Head       1021       2747      0.971      0.918      0.954      0.875\n",
      "                Helmet       1021        541      0.965      0.872       0.92      0.595\n",
      "                 Pants       1021       1682       0.86      0.713      0.812      0.601\n",
      "                 Shirt       1021       2333      0.938      0.889      0.932      0.737\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\0.001_0.0001_0.9_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.0001_0.9_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.783      0.623      0.711      0.513\n",
      "                  Belt       1021         10          0          0          0          0\n",
      "                  Face       1021       1904      0.947      0.915      0.947      0.745\n",
      "                 Glove       1021        195      0.653      0.328      0.467      0.287\n",
      "               Goggles       1021        107      0.792      0.178      0.491      0.232\n",
      "                  Hand       1021       2406      0.913      0.786      0.864      0.537\n",
      "                  Head       1021       2747       0.97      0.919      0.955      0.877\n",
      "                Helmet       1021        541      0.963      0.865      0.915        0.6\n",
      "                 Pants       1021       1682      0.872      0.725      0.822      0.605\n",
      "                 Shirt       1021       2333      0.935      0.895      0.937      0.737\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving testing\\0.001_0.0001_0.9_True\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.0001_0.9_True\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.867      0.656      0.774      0.537\n",
      "                  Belt       1021         10      0.667        0.2      0.465      0.159\n",
      "                  Face       1021       1904      0.949       0.92       0.95      0.745\n",
      "                 Glove       1021        195      0.657      0.333      0.486       0.29\n",
      "               Goggles       1021        107      0.857       0.28      0.574      0.273\n",
      "                  Hand       1021       2406      0.913      0.787      0.868      0.543\n",
      "                  Head       1021       2747      0.971      0.921      0.955      0.879\n",
      "                Helmet       1021        541      0.965      0.874      0.921      0.598\n",
      "                 Pants       1021       1682       0.88      0.705      0.812      0.602\n",
      "                 Shirt       1021       2333      0.944      0.883      0.932       0.74\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\0.001_0.001_0.95_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.001_0.95_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.865      0.671       0.78      0.542\n",
      "                  Belt       1021         10        0.6        0.3      0.458      0.191\n",
      "                  Face       1021       1904       0.95      0.924      0.951      0.746\n",
      "                 Glove       1021        195      0.681      0.328      0.499      0.285\n",
      "               Goggles       1021        107      0.895      0.318      0.621      0.289\n",
      "                  Hand       1021       2406       0.91       0.78      0.864      0.544\n",
      "                  Head       1021       2747      0.972      0.921      0.956      0.878\n",
      "                Helmet       1021        541      0.967      0.871       0.92      0.601\n",
      "                 Pants       1021       1682       0.87      0.707      0.813      0.602\n",
      "                 Shirt       1021       2333      0.938      0.887      0.933      0.739\n",
      "Speed: 0.6ms preprocess, 2.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\0.001_0.001_0.95_True\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.001_0.95_True\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.785      0.629      0.718      0.516\n",
      "                  Belt       1021         10          0          0          0          0\n",
      "                  Face       1021       1904      0.946      0.914      0.946      0.746\n",
      "                 Glove       1021        195       0.67      0.323      0.498      0.289\n",
      "               Goggles       1021        107      0.769       0.28      0.548       0.25\n",
      "                  Hand       1021       2406       0.92      0.776      0.864      0.542\n",
      "                  Head       1021       2747      0.973      0.914      0.951      0.875\n",
      "                Helmet       1021        541      0.969      0.861      0.916      0.602\n",
      "                 Pants       1021       1682      0.875      0.706      0.806        0.6\n",
      "                 Shirt       1021       2333      0.947      0.881      0.932      0.737\n",
      "Speed: 0.7ms preprocess, 2.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\0.001_0.001_0.9_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.001_0.9_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.828      0.649      0.747      0.526\n",
      "                  Belt       1021         10      0.333        0.1      0.199     0.0398\n",
      "                  Face       1021       1904      0.952      0.921      0.953      0.752\n",
      "                 Glove       1021        195      0.677      0.344      0.519      0.321\n",
      "               Goggles       1021        107      0.791      0.318      0.563      0.258\n",
      "                  Hand       1021       2406      0.919      0.779      0.864      0.542\n",
      "                  Head       1021       2747      0.976      0.918      0.953      0.877\n",
      "                Helmet       1021        541      0.974      0.884      0.932      0.602\n",
      "                 Pants       1021       1682      0.888      0.699       0.81      0.599\n",
      "                 Shirt       1021       2333      0.945       0.88      0.931      0.739\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Saving testing\\0.001_0.001_0.9_True\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\0.001_0.001_0.9_True\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.801      0.621      0.722      0.517\n",
      "                  Belt       1021         10          0          0          0          0\n",
      "                  Face       1021       1904      0.961      0.901      0.943      0.743\n",
      "                 Glove       1021        195      0.745      0.359      0.564      0.339\n",
      "               Goggles       1021        107      0.812      0.243      0.534       0.24\n",
      "                  Hand       1021       2406      0.925       0.75      0.854      0.537\n",
      "                  Head       1021       2747       0.98      0.912      0.952      0.875\n",
      "                Helmet       1021        541      0.968      0.847       0.91      0.594\n",
      "                 Pants       1021       1682      0.873      0.705      0.813      0.601\n",
      "                 Shirt       1021       2333      0.945      0.873      0.926       0.73\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\1e-05_0.0001_0.95_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.0001_0.95_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.858      0.646      0.763      0.535\n",
      "                  Belt       1021         10      0.667        0.2      0.432      0.184\n",
      "                  Face       1021       1904      0.952      0.921      0.951      0.747\n",
      "                 Glove       1021        195      0.705      0.318      0.501      0.292\n",
      "               Goggles       1021        107      0.743      0.243       0.51      0.245\n",
      "                  Hand       1021       2406      0.909      0.761      0.852      0.536\n",
      "                  Head       1021       2747       0.97      0.914      0.952      0.875\n",
      "                Helmet       1021        541      0.963      0.858      0.919      0.593\n",
      "                 Pants       1021       1682      0.875      0.714      0.814      0.603\n",
      "                 Shirt       1021       2333      0.944      0.883      0.932      0.736\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\1e-05_0.0001_0.95_True7\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.0001_0.95_True7\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.819      0.652      0.748      0.536\n",
      "                  Belt       1021         10        0.2        0.1      0.186      0.093\n",
      "                  Face       1021       1904      0.943      0.926      0.953      0.747\n",
      "                 Glove       1021        195      0.717      0.364      0.521      0.318\n",
      "               Goggles       1021        107       0.81      0.318      0.586      0.307\n",
      "                  Hand       1021       2406      0.912      0.784      0.867      0.541\n",
      "                  Head       1021       2747      0.975       0.92      0.954      0.876\n",
      "                Helmet       1021        541      0.962      0.891      0.931      0.601\n",
      "                 Pants       1021       1682      0.902      0.692       0.81       0.61\n",
      "                 Shirt       1021       2333       0.95      0.874      0.927      0.731\n",
      "Speed: 0.6ms preprocess, 2.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\1e-05_0.0001_0.9_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.0001_0.9_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.848      0.649       0.76      0.527\n",
      "                  Belt       1021         10        0.5        0.2      0.364      0.115\n",
      "                  Face       1021       1904      0.953       0.91      0.945      0.741\n",
      "                 Glove       1021        195      0.698      0.344      0.525      0.325\n",
      "               Goggles       1021        107      0.812      0.243      0.527      0.224\n",
      "                  Hand       1021       2406      0.913      0.769      0.859      0.536\n",
      "                  Head       1021       2747      0.976      0.909      0.951      0.871\n",
      "                Helmet       1021        541      0.963       0.86      0.913      0.591\n",
      "                 Pants       1021       1682      0.866      0.719      0.817      0.603\n",
      "                 Shirt       1021       2333      0.948      0.892      0.937      0.738\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\1e-05_0.0001_0.9_True\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.0001_0.9_True\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:22<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.904      0.661      0.794      0.553\n",
      "                  Belt       1021         10          1        0.2        0.6      0.272\n",
      "                  Face       1021       1904       0.95      0.924      0.951      0.745\n",
      "                 Glove       1021        195      0.696      0.364      0.527      0.308\n",
      "               Goggles       1021        107      0.825      0.308      0.583       0.29\n",
      "                  Hand       1021       2406      0.914      0.786      0.868      0.545\n",
      "                  Head       1021       2747      0.975      0.922      0.956      0.881\n",
      "                Helmet       1021        541      0.963      0.867      0.917      0.598\n",
      "                 Pants       1021       1682      0.873      0.696      0.809      0.599\n",
      "                 Shirt       1021       2333      0.939      0.883      0.932      0.738\n",
      "Speed: 0.6ms preprocess, 2.9ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Saving testing\\1e-05_0.001_0.95_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.001_0.95_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:24<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.849      0.639       0.75      0.523\n",
      "                  Belt       1021         10        0.5        0.1      0.275      0.055\n",
      "                  Face       1021       1904       0.95      0.915      0.946      0.744\n",
      "                 Glove       1021        195      0.681      0.318      0.496      0.286\n",
      "               Goggles       1021        107      0.833       0.28      0.563      0.268\n",
      "                  Hand       1021       2406      0.904      0.783      0.863      0.543\n",
      "                  Head       1021       2747      0.977      0.916      0.954      0.876\n",
      "                Helmet       1021        541      0.963      0.854      0.912      0.591\n",
      "                 Pants       1021       1682      0.883      0.702      0.811      0.607\n",
      "                 Shirt       1021       2333       0.95      0.882      0.933       0.74\n",
      "Speed: 0.6ms preprocess, 3.0ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Saving testing\\1e-05_0.001_0.95_True\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.001_0.95_True\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 8/8 [00:24<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1021      11925      0.846      0.635      0.748      0.517\n",
      "                  Belt       1021         10        0.5        0.1      0.275      0.055\n",
      "                  Face       1021       1904      0.955      0.898      0.938      0.738\n",
      "                 Glove       1021        195      0.631      0.333      0.497      0.283\n",
      "               Goggles       1021        107      0.871      0.252      0.563      0.242\n",
      "                  Hand       1021       2406      0.899      0.781      0.861      0.537\n",
      "                  Head       1021       2747      0.975      0.915      0.954      0.875\n",
      "                Helmet       1021        541      0.966       0.85      0.912      0.591\n",
      "                 Pants       1021       1682      0.876      0.696      0.803      0.598\n",
      "                 Shirt       1021       2333      0.939      0.887      0.933      0.735\n",
      "Speed: 0.8ms preprocess, 2.9ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Saving testing\\1e-05_0.001_0.9_False\\predictions.json...\n",
      "Results saved to \u001b[1mtesting\\1e-05_0.001_0.9_False\u001b[0m\n",
      "Ultralytics YOLOv8.2.2  Python-3.10.13 torch-2.2.1+cu118 CUDA:0 (NVIDIA A100-SXM4-40GB, 40654MiB)\n",
      "Model summary (fused): 268 layers, 43618944 parameters, 0 gradients, 164.9 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Nadim\\Desktop\\Exp_nadim\\labels\\test.cache... 1021 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1021/1021 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING  C:\\Users\\Nadim\\Desktop\\Exp_nadim\\images\\test\\ppe_0147.jpg: corrupt JPEG restored and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  62%|██████▎   | 5/8 [00:25<00:15,  5.13s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 22288) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(model_path)\n\u001b[0;32m     21\u001b[0m testing_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model_path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m---> 22\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mval(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtesting_kwargs)\n\u001b[0;32m     23\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\ultralytics\\engine\\model.py:527\u001b[0m, in \u001b[0;36mModel.val\u001b[1;34m(self, validator, **kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m    526\u001b[0m validator \u001b[38;5;241m=\u001b[39m (validator \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidator\u001b[39m\u001b[38;5;124m\"\u001b[39m))(args\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[1;32m--> 527\u001b[0m \u001b[43mvalidator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m validator\u001b[38;5;241m.\u001b[39mmetrics\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validator\u001b[38;5;241m.\u001b[39mmetrics\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\ultralytics\\engine\\validator.py:169\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[1;34m(self, trainer, model)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_metrics(de_parallel(model))\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjdict \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# empty before each val\u001b[39;00m\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(bar):\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_val_batch_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_i \u001b[38;5;241m=\u001b[39m batch_i\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\ultralytics\\data\\build.py:50\u001b[0m, in \u001b[0;36mInfiniteDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a sampler that repeats indefinitely.\"\"\"\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)):\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1284\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1285\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1286\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1287\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Nadim\\.conda\\envs\\ultra10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 22288) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "from pathlib import Path as P\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "models = P().glob(\"training/*/weights/best.pt\")\n",
    "results = []\n",
    "\n",
    "testing_kwargs = {\n",
    "    \"data\": \"./nadim_data.yaml\",\n",
    "    \"split\": \"test\",\n",
    "    \"device\": \"0\",\n",
    "    \"batch\": 128,\n",
    "    \"project\": \"testing\",\n",
    "    \"conf\": 0.5,\n",
    "    \"plots\": True\n",
    "}\n",
    "\n",
    "for model_path in models:\n",
    "    model = YOLO(model_path)\n",
    "    testing_kwargs[\"name\"] = model_path.parent.parent.name\n",
    "    result = model.val(**testing_kwargs)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'run': '0.001_0.0001_0.95_False',\n",
       "  'metrics/precision(B)': 0.7906811758540333,\n",
       "  'metrics/recall(B)': 0.633468819631319,\n",
       "  'metrics/mAP50(B)': 0.7191961725155969,\n",
       "  'metrics/mAP50-95(B)': 0.5175180432977279,\n",
       "  'fitness': 0.5376858562195148},\n",
       " 1: {'run': '0.001_0.0001_0.95_True',\n",
       "  'metrics/precision(B)': 0.8039346983571399,\n",
       "  'metrics/recall(B)': 0.5998483930974643,\n",
       "  'metrics/mAP50(B)': 0.7127146116830836,\n",
       "  'metrics/mAP50-95(B)': 0.5097556774176408,\n",
       "  'fitness': 0.5300515708441851},\n",
       " 2: {'run': '0.001_0.0001_0.9_False',\n",
       "  'metrics/precision(B)': 0.9003254124604622,\n",
       "  'metrics/recall(B)': 0.6441910272913014,\n",
       "  'metrics/mAP50(B)': 0.781861714537778,\n",
       "  'metrics/mAP50-95(B)': 0.5286462018984482,\n",
       "  'fitness': 0.5539677531623812},\n",
       " 3: {'run': '0.001_0.0001_0.9_True',\n",
       "  'metrics/precision(B)': 0.7827305448714257,\n",
       "  'metrics/recall(B)': 0.623401077161098,\n",
       "  'metrics/mAP50(B)': 0.711002235573267,\n",
       "  'metrics/mAP50-95(B)': 0.5132949897962882,\n",
       "  'fitness': 0.5330657143739861},\n",
       " 4: {'run': '0.001_0.001_0.95_False',\n",
       "  'metrics/precision(B)': 0.8670025823111731,\n",
       "  'metrics/recall(B)': 0.6559597175308217,\n",
       "  'metrics/mAP50(B)': 0.7736413581747342,\n",
       "  'metrics/mAP50-95(B)': 0.5365516366128534,\n",
       "  'fitness': 0.5602606087690416},\n",
       " 5: {'run': '0.001_0.001_0.95_True',\n",
       "  'metrics/precision(B)': 0.8648394615145468,\n",
       "  'metrics/recall(B)': 0.6707056113833705,\n",
       "  'metrics/mAP50(B)': 0.779570703310836,\n",
       "  'metrics/mAP50-95(B)': 0.5417580299776478,\n",
       "  'fitness': 0.5655392973109666},\n",
       " 6: {'run': '0.001_0.001_0.9_False',\n",
       "  'metrics/precision(B)': 0.7853884739337205,\n",
       "  'metrics/recall(B)': 0.6286249560692866,\n",
       "  'metrics/mAP50(B)': 0.7178765596179284,\n",
       "  'metrics/mAP50-95(B)': 0.5155420520069393,\n",
       "  'fitness': 0.5357755027680382},\n",
       " 7: {'run': '0.001_0.001_0.9_True',\n",
       "  'metrics/precision(B)': 0.8282687018243583,\n",
       "  'metrics/recall(B)': 0.6490778202521351,\n",
       "  'metrics/mAP50(B)': 0.7470274728801111,\n",
       "  'metrics/mAP50-95(B)': 0.5255511408476057,\n",
       "  'fitness': 0.5476987740508562},\n",
       " 8: {'run': '1e-05_0.0001_0.95_False',\n",
       "  'metrics/precision(B)': 0.8010248215771273,\n",
       "  'metrics/recall(B)': 0.6209577730951127,\n",
       "  'metrics/mAP50(B)': 0.7216206724070364,\n",
       "  'metrics/mAP50-95(B)': 0.5174622030067646,\n",
       "  'fitness': 0.5378780499467918},\n",
       " 9: {'run': '1e-05_0.0001_0.95_True7',\n",
       "  'metrics/precision(B)': 0.8584714338570694,\n",
       "  'metrics/recall(B)': 0.6457537876632956,\n",
       "  'metrics/mAP50(B)': 0.7625288891590272,\n",
       "  'metrics/mAP50-95(B)': 0.5345252500189862,\n",
       "  'fitness': 0.5573256139329903},\n",
       " 10: {'run': '1e-05_0.0001_0.9_False',\n",
       "  'metrics/precision(B)': 0.8189707403681603,\n",
       "  'metrics/recall(B)': 0.6522074554268082,\n",
       "  'metrics/mAP50(B)': 0.7484031354155355,\n",
       "  'metrics/mAP50-95(B)': 0.5359694073072393,\n",
       "  'fitness': 0.557212780118069},\n",
       " 11: {'run': '1e-05_0.0001_0.9_True',\n",
       "  'metrics/precision(B)': 0.8475989482598894,\n",
       "  'metrics/recall(B)': 0.6492939351093884,\n",
       "  'metrics/mAP50(B)': 0.7596318261443454,\n",
       "  'metrics/mAP50-95(B)': 0.5272344067237398,\n",
       "  'fitness': 0.5504741486658004},\n",
       " 12: {'run': '1e-05_0.001_0.95_False',\n",
       "  'metrics/precision(B)': 0.9038575645394666,\n",
       "  'metrics/recall(B)': 0.6611367660028474,\n",
       "  'metrics/mAP50(B)': 0.7936318435863856,\n",
       "  'metrics/mAP50-95(B)': 0.5527081837135167,\n",
       "  'fitness': 0.5768005497008036},\n",
       " 13: {'run': '1e-05_0.001_0.95_True',\n",
       "  'metrics/precision(B)': 0.8491435740757123,\n",
       "  'metrics/recall(B)': 0.638870565835531,\n",
       "  'metrics/mAP50(B)': 0.7503978324831331,\n",
       "  'metrics/mAP50-95(B)': 0.5233904753778809,\n",
       "  'fitness': 0.5460912110884061},\n",
       " 14: {'run': '1e-05_0.001_0.9_False',\n",
       "  'metrics/precision(B)': 0.8457845146444681,\n",
       "  'metrics/recall(B)': 0.6347471689740919,\n",
       "  'metrics/mAP50(B)': 0.7483903111608304,\n",
       "  'metrics/mAP50-95(B)': 0.5172296799587954,\n",
       "  'fitness': 0.540345743078999}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for i, result in enumerate(results):\n",
    "    results_dict[i] = {\"run\": result.save_dir.name, **result.results_dict}\n",
    "# results[0].results_dict\n",
    "\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>metrics/precision(B)</th>\n",
       "      <th>metrics/recall(B)</th>\n",
       "      <th>metrics/mAP50(B)</th>\n",
       "      <th>metrics/mAP50-95(B)</th>\n",
       "      <th>fitness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001_0.0001_0.95_False</td>\n",
       "      <td>0.790681</td>\n",
       "      <td>0.633469</td>\n",
       "      <td>0.719196</td>\n",
       "      <td>0.517518</td>\n",
       "      <td>0.537686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001_0.0001_0.95_True</td>\n",
       "      <td>0.803935</td>\n",
       "      <td>0.599848</td>\n",
       "      <td>0.712715</td>\n",
       "      <td>0.509756</td>\n",
       "      <td>0.530052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001_0.0001_0.9_False</td>\n",
       "      <td>0.900325</td>\n",
       "      <td>0.644191</td>\n",
       "      <td>0.781862</td>\n",
       "      <td>0.528646</td>\n",
       "      <td>0.553968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001_0.0001_0.9_True</td>\n",
       "      <td>0.782731</td>\n",
       "      <td>0.623401</td>\n",
       "      <td>0.711002</td>\n",
       "      <td>0.513295</td>\n",
       "      <td>0.533066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001_0.001_0.95_False</td>\n",
       "      <td>0.867003</td>\n",
       "      <td>0.65596</td>\n",
       "      <td>0.773641</td>\n",
       "      <td>0.536552</td>\n",
       "      <td>0.560261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001_0.001_0.95_True</td>\n",
       "      <td>0.864839</td>\n",
       "      <td>0.670706</td>\n",
       "      <td>0.779571</td>\n",
       "      <td>0.541758</td>\n",
       "      <td>0.565539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001_0.001_0.9_False</td>\n",
       "      <td>0.785388</td>\n",
       "      <td>0.628625</td>\n",
       "      <td>0.717877</td>\n",
       "      <td>0.515542</td>\n",
       "      <td>0.535776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.001_0.001_0.9_True</td>\n",
       "      <td>0.828269</td>\n",
       "      <td>0.649078</td>\n",
       "      <td>0.747027</td>\n",
       "      <td>0.525551</td>\n",
       "      <td>0.547699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1e-05_0.0001_0.95_False</td>\n",
       "      <td>0.801025</td>\n",
       "      <td>0.620958</td>\n",
       "      <td>0.721621</td>\n",
       "      <td>0.517462</td>\n",
       "      <td>0.537878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1e-05_0.0001_0.95_True7</td>\n",
       "      <td>0.858471</td>\n",
       "      <td>0.645754</td>\n",
       "      <td>0.762529</td>\n",
       "      <td>0.534525</td>\n",
       "      <td>0.557326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1e-05_0.0001_0.9_False</td>\n",
       "      <td>0.818971</td>\n",
       "      <td>0.652207</td>\n",
       "      <td>0.748403</td>\n",
       "      <td>0.535969</td>\n",
       "      <td>0.557213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1e-05_0.0001_0.9_True</td>\n",
       "      <td>0.847599</td>\n",
       "      <td>0.649294</td>\n",
       "      <td>0.759632</td>\n",
       "      <td>0.527234</td>\n",
       "      <td>0.550474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1e-05_0.001_0.95_False</td>\n",
       "      <td>0.903858</td>\n",
       "      <td>0.661137</td>\n",
       "      <td>0.793632</td>\n",
       "      <td>0.552708</td>\n",
       "      <td>0.576801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1e-05_0.001_0.95_True</td>\n",
       "      <td>0.849144</td>\n",
       "      <td>0.638871</td>\n",
       "      <td>0.750398</td>\n",
       "      <td>0.52339</td>\n",
       "      <td>0.546091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1e-05_0.001_0.9_False</td>\n",
       "      <td>0.845785</td>\n",
       "      <td>0.634747</td>\n",
       "      <td>0.74839</td>\n",
       "      <td>0.51723</td>\n",
       "      <td>0.540346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        run metrics/precision(B) metrics/recall(B)  \\\n",
       "0   0.001_0.0001_0.95_False             0.790681          0.633469   \n",
       "1    0.001_0.0001_0.95_True             0.803935          0.599848   \n",
       "2    0.001_0.0001_0.9_False             0.900325          0.644191   \n",
       "3     0.001_0.0001_0.9_True             0.782731          0.623401   \n",
       "4    0.001_0.001_0.95_False             0.867003           0.65596   \n",
       "5     0.001_0.001_0.95_True             0.864839          0.670706   \n",
       "6     0.001_0.001_0.9_False             0.785388          0.628625   \n",
       "7      0.001_0.001_0.9_True             0.828269          0.649078   \n",
       "8   1e-05_0.0001_0.95_False             0.801025          0.620958   \n",
       "9   1e-05_0.0001_0.95_True7             0.858471          0.645754   \n",
       "10   1e-05_0.0001_0.9_False             0.818971          0.652207   \n",
       "11    1e-05_0.0001_0.9_True             0.847599          0.649294   \n",
       "12   1e-05_0.001_0.95_False             0.903858          0.661137   \n",
       "13    1e-05_0.001_0.95_True             0.849144          0.638871   \n",
       "14    1e-05_0.001_0.9_False             0.845785          0.634747   \n",
       "\n",
       "   metrics/mAP50(B) metrics/mAP50-95(B)   fitness  \n",
       "0          0.719196            0.517518  0.537686  \n",
       "1          0.712715            0.509756  0.530052  \n",
       "2          0.781862            0.528646  0.553968  \n",
       "3          0.711002            0.513295  0.533066  \n",
       "4          0.773641            0.536552  0.560261  \n",
       "5          0.779571            0.541758  0.565539  \n",
       "6          0.717877            0.515542  0.535776  \n",
       "7          0.747027            0.525551  0.547699  \n",
       "8          0.721621            0.517462  0.537878  \n",
       "9          0.762529            0.534525  0.557326  \n",
       "10         0.748403            0.535969  0.557213  \n",
       "11         0.759632            0.527234  0.550474  \n",
       "12         0.793632            0.552708  0.576801  \n",
       "13         0.750398             0.52339  0.546091  \n",
       "14          0.74839             0.51723  0.540346  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results_dict).T\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | run                     |   metrics/precision(B) |   metrics/recall(B) |   metrics/mAP50(B) |   metrics/mAP50-95(B) |   fitness |\n",
      "|---:|:------------------------|-----------------------:|--------------------:|-------------------:|----------------------:|----------:|\n",
      "| 12 | 1e-05_0.001_0.95_False  |               0.903858 |            0.661137 |           0.793632 |              0.552708 |  0.576801 |\n",
      "|  2 | 0.001_0.0001_0.9_False  |               0.900325 |            0.644191 |           0.781862 |              0.528646 |  0.553968 |\n",
      "|  5 | 0.001_0.001_0.95_True   |               0.864839 |            0.670706 |           0.779571 |              0.541758 |  0.565539 |\n",
      "|  4 | 0.001_0.001_0.95_False  |               0.867003 |            0.65596  |           0.773641 |              0.536552 |  0.560261 |\n",
      "|  9 | 1e-05_0.0001_0.95_True7 |               0.858471 |            0.645754 |           0.762529 |              0.534525 |  0.557326 |\n"
     ]
    }
   ],
   "source": [
    "print(df.sort_values(ascending=False, by=\"metrics/mAP50(B)\").head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | run                     |   metrics/precision(B) |   metrics/recall(B) |   metrics/mAP50(B) |   metrics/mAP50-95(B) |   fitness |\n",
      "|---:|:------------------------|-----------------------:|--------------------:|-------------------:|----------------------:|----------:|\n",
      "| 12 | 1e-05_0.001_0.95_False  |               0.903858 |            0.661137 |           0.793632 |              0.552708 |  0.576801 |\n",
      "|  2 | 0.001_0.0001_0.9_False  |               0.900325 |            0.644191 |           0.781862 |              0.528646 |  0.553968 |\n",
      "|  4 | 0.001_0.001_0.95_False  |               0.867003 |            0.65596  |           0.773641 |              0.536552 |  0.560261 |\n",
      "|  5 | 0.001_0.001_0.95_True   |               0.864839 |            0.670706 |           0.779571 |              0.541758 |  0.565539 |\n",
      "|  9 | 1e-05_0.0001_0.95_True7 |               0.858471 |            0.645754 |           0.762529 |              0.534525 |  0.557326 |\n"
     ]
    }
   ],
   "source": [
    "print(df.sort_values(ascending=False, by=\"metrics/precision(B)\").head().to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | run                    |   metrics/precision(B) |   metrics/recall(B) |   metrics/mAP50(B) |   metrics/mAP50-95(B) |   fitness |\n",
      "|---:|:-----------------------|-----------------------:|--------------------:|-------------------:|----------------------:|----------:|\n",
      "|  5 | 0.001_0.001_0.95_True  |               0.864839 |            0.670706 |           0.779571 |              0.541758 |  0.565539 |\n",
      "| 12 | 1e-05_0.001_0.95_False |               0.903858 |            0.661137 |           0.793632 |              0.552708 |  0.576801 |\n",
      "|  4 | 0.001_0.001_0.95_False |               0.867003 |            0.65596  |           0.773641 |              0.536552 |  0.560261 |\n",
      "| 10 | 1e-05_0.0001_0.9_False |               0.818971 |            0.652207 |           0.748403 |              0.535969 |  0.557213 |\n",
      "| 11 | 1e-05_0.0001_0.9_True  |               0.847599 |            0.649294 |           0.759632 |              0.527234 |  0.550474 |\n"
     ]
    }
   ],
   "source": [
    "print(df.sort_values(ascending=False, by=\"metrics/recall(B)\").head().to_markdown())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultra10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
